{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UM2oJy-ag5H3",
    "outputId": "de66a4cb-5fe8-4e57-c220-fcad944c9c27"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = False\n",
    "\n",
    "# if in colab, make colab setup\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    IN_COLAB = True\n",
    "    ZIP_PATH = \"/content/drive/MyDrive/embedded_ml_data/VOCdevkit.zip\"\n",
    "    FILENAME = \"dev-notebook.ipynb\"\n",
    "    BRANCH = \"michael\"\n",
    "    !git clone -b $BRANCH https://github.com/yannickfunk/EmbeddedMLLab tmp\n",
    "    !rm tmp/$FILENAME\n",
    "    !mv tmp/* .\n",
    "    !rm -rf tmp\n",
    "    !rm -rf sample_data\n",
    "    !pip install -r requirements.txt\n",
    "\n",
    "    # setup data\n",
    "    !cp  $ZIP_PATH data/\n",
    "    %pushd data\n",
    "    !unzip -qq VOCdevkit.zip\n",
    "    %popd\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "\n",
    "# sys.path.append('../')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Tensorboard logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "if IN_COLAB == True:\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir $LOGDIR\n",
    "   \n",
    "tensorboard = pl.loggers.TensorBoardLogger(save_dir=\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "from models.tinyyolov2 import TinyYoloV2PersonOnly\n",
    "import pytorch_lightning as pl\n",
    "from utils.dataloader import VOCDataModule\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=30, auto_scale_batch_size='binsearch',accelerator='auto', logger=tensorboard, fast_dev_run=not IN_COLAB)\n",
    "\n",
    "\n",
    "model = TinyYoloV2PersonOnly()\n",
    "model.load_pt_from_disk(DATA_PATH + '/voc_pretrained.pt')\n",
    "\n",
    "data= VOCDataModule(person_only=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michael\\miniconda3\\envs\\embedded-ml\\lib\\site-packages\\pytorch_lightning\\tuner\\batch_size_scaling.py:38: UserWarning: Skipping batch size scaler since `fast_dev_run` is enabled.\n",
      "  rank_zero_warn(\"Skipping batch size scaler since `fast_dev_run` is enabled.\")\n",
      "\n",
      "   | Name  | Type            | Params\n",
      "-------------------------------------------\n",
      "0  | loss  | YoloLoss        | 0     \n",
      "1  | pad   | ReflectionPad2d | 0     \n",
      "2  | conv1 | Conv2d          | 432   \n",
      "3  | bn1   | BatchNorm2d     | 32    \n",
      "4  | conv2 | Conv2d          | 4.6 K \n",
      "5  | bn2   | BatchNorm2d     | 64    \n",
      "6  | conv3 | Conv2d          | 18.4 K\n",
      "7  | bn3   | BatchNorm2d     | 128   \n",
      "8  | conv4 | Conv2d          | 73.7 K\n",
      "9  | bn4   | BatchNorm2d     | 256   \n",
      "10 | conv5 | Conv2d          | 294 K \n",
      "11 | bn5   | BatchNorm2d     | 512   \n",
      "12 | conv6 | Conv2d          | 1.2 M \n",
      "13 | bn6   | BatchNorm2d     | 1.0 K \n",
      "14 | conv7 | Conv2d          | 4.7 M \n",
      "15 | bn7   | BatchNorm2d     | 2.0 K \n",
      "16 | conv8 | Conv2d          | 9.4 M \n",
      "17 | bn8   | BatchNorm2d     | 2.0 K \n",
      "18 | conv9 | Conv2d          | 30.8 K\n",
      "-------------------------------------------\n",
      "9.5 M     Trainable params\n",
      "6.3 M     Non-trainable params\n",
      "15.8 M    Total params\n",
      "63.058    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layers: conv1.weight, bn1.weight, bn1.bias, conv2.weight, bn2.weight, bn2.bias, conv3.weight, bn3.weight, bn3.bias, conv4.weight, bn4.weight, bn4.bias, conv5.weight, bn5.weight, bn5.bias, conv6.weight, bn6.weight, bn6.bias, conv7.weight, bn7.weight, bn7.bias, \n",
      "Freezing layers: conv1.weight, bn1.weight, bn1.bias, conv2.weight, bn2.weight, bn2.bias, conv3.weight, bn3.weight, bn3.bias, conv4.weight, bn4.weight, bn4.bias, conv5.weight, bn5.weight, bn5.bias, conv6.weight, bn6.weight, bn6.bias, conv7.weight, bn7.weight, bn7.bias, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michael\\miniconda3\\envs\\embedded-ml\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\Michael\\miniconda3\\envs\\embedded-ml\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1558: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\Michael\\miniconda3\\envs\\embedded-ml\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\Michael\\miniconda3\\envs\\embedded-ml\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc4c9a94c0b4842813d2f68a0bb8de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michael\\miniconda3\\envs\\embedded-ml\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea2dccdd8cd4423a3b8e069aac6abcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.tune(model, data)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbfbde83ea5ffc555830b2add588da7cea02368f7c2cdb0f2f81ff2a0f3ac2ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
