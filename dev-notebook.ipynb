{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UM2oJy-ag5H3",
    "outputId": "de66a4cb-5fe8-4e57-c220-fcad944c9c27"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "IN_COLAB = False\n",
    "DATA_PATH = \"data/\"\n",
    "\n",
    "# if in colab, make colab setup\n",
    "if 'google.colab' in sys.modules:\n",
    "    \n",
    "    IN_COLAB = True\n",
    "    SSH_DIR = '/root/.ssh'\n",
    "    ZIP_PATH = \"/content/drive/MyDrive/embedded_ml_data/VOCdevkit.zip\"\n",
    "    FILENAME = \"dev-notebook.ipynb\"\n",
    "    BRANCH = \"michael\"\n",
    "\n",
    "    # Setup ssh-auth to github\n",
    "    try:\n",
    "        os.makedirs(SSH_DIR)\n",
    "    except FileExistsError:\n",
    "        # directory already exists\n",
    "        pass\n",
    "\n",
    "    !ssh-keyscan github.com >> /root/.ssh/known_hosts\n",
    "    !echo 'PUBKEY' > /root/.ssh/id_rsa.pub\n",
    "    !echo -e \"PRIVKEY\" > /root/.ssh/id_rsa\n",
    "    !chmod 644 /root/.ssh/known_hosts\n",
    "    !chmod 600 /root/.ssh/id_rsa\n",
    "    !ssh -T git@github.com\n",
    "\n",
    "    # Setup working environment\n",
    "    !rm -rf models\n",
    "    !rm -rf utils\n",
    "    !git clone -b $BRANCH https://github.com/yannickfunk/EmbeddedMLLab tmp\n",
    "    !rm tmp/$FILENAME\n",
    "    !mv tmp/* .\n",
    "    !rm -rf tmp\n",
    "    !rm -rf sample_data\n",
    "    %pip install -r requirements.txt\n",
    "\n",
    "    # Setup data\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    try:\n",
    "      os.makedirs('./data')\n",
    "    except FileExistsError:\n",
    "      # directory already exists\n",
    "      pass\n",
    "    !cp  $ZIP_PATH data/\n",
    "    %pushd data\n",
    "    !unzip -qq VOCdevkit.zip\n",
    "    %popd\n",
    "    drive.flush_and_unmount()\n",
    "\n",
    "    \n",
    "try:\n",
    "    os.makedirs('./checkpoints')\n",
    "    os.makedirs('./checkpoints/results')\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Tensorboard logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 112020), started 0:06:51 ago. (Use '!kill 112020' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6b53aee164199538\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6b53aee164199538\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup logger\n",
    "import lightning as pl\n",
    "\n",
    "LOGDIR='logs'\n",
    "TENSORBOARD_DIR=LOGDIR+'/lightning_logs'\n",
    "\n",
    "tensorboard = pl.pytorch.loggers.TensorBoardLogger(save_dir=LOGDIR, default_hp_metric=True, log_graph=True)\n",
    "\n",
    "try:\n",
    "    os.makedirs('./'+LOGDIR+'/lightning_logs')\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $TENSORBOARD_DIR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "from models.tinyyolov2 import TinyYoloV2PersonOnly\n",
    "import lightning as pl\n",
    "import torch\n",
    "\n",
    "from utils.dataloader import VOCDataModule\n",
    "\n",
    "from lightning.pytorch.callbacks.lr_monitor import LearningRateMonitor\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from utils.dataloader import CAPTCHADataModule\n",
    "\n",
    "import nni\n",
    "from nni.compression.pytorch import LightningEvaluator\n",
    "\n",
    "\n",
    "# Setting up callbacks\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", mode='min', verbose=True)\n",
    "checkpointing = ModelCheckpoint(\n",
    "    save_top_k=3,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    verbose=True,\n",
    "    auto_insert_metric_name=True,\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "trainer = nni.trace(pl.Trainer)(\n",
    "    max_epochs=25,\n",
    "    auto_lr_find=True,\n",
    "    auto_scale_batch_size='binsearch',\n",
    "    accelerator=\"auto\",\n",
    "    devices=[0] if torch.cuda.is_available() else None,\n",
    "    accumulate_grad_batches=1,\n",
    "    logger=tensorboard,\n",
    "    log_every_n_steps=1,\n",
    "    fast_dev_run= True if not torch.cuda.is_available() else False,\n",
    "    callbacks=[\n",
    "    lr_monitor,\n",
    "    early_stopping,\n",
    "    checkpointing\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "model = TinyYoloV2PersonOnly()\n",
    "model.load_pt_from_disk(DATA_PATH + \"/voc_pretrained.pt\")\n",
    "\n",
    "data = nni.trace(VOCDataModule)(person_only=True)\n",
    "\n",
    "evaluator = LightningEvaluator(trainer, data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michael\\miniconda3\\envs\\embedded-ml\\lib\\site-packages\\lightning\\pytorch\\tuner\\batch_size_scaling.py:38: UserWarning: Skipping batch size scaler since `fast_dev_run` is enabled.\n",
      "  rank_zero_warn(\"Skipping batch size scaler since `fast_dev_run` is enabled.\")\n",
      "\n",
      "   | Name  | Type            | Params\n",
      "-------------------------------------------\n",
      "0  | loss  | YoloLoss        | 0     \n",
      "1  | pad   | ReflectionPad2d | 0     \n",
      "2  | conv1 | Conv2d          | 432   \n",
      "3  | bn1   | BatchNorm2d     | 32    \n",
      "4  | conv2 | Conv2d          | 4.6 K \n",
      "5  | bn2   | BatchNorm2d     | 64    \n",
      "6  | conv3 | Conv2d          | 18.4 K\n",
      "7  | bn3   | BatchNorm2d     | 128   \n",
      "8  | conv4 | Conv2d          | 73.7 K\n",
      "9  | bn4   | BatchNorm2d     | 256   \n",
      "10 | conv5 | Conv2d          | 294 K \n",
      "11 | bn5   | BatchNorm2d     | 512   \n",
      "12 | conv6 | Conv2d          | 1.2 M \n",
      "13 | bn6   | BatchNorm2d     | 1.0 K \n",
      "14 | conv7 | Conv2d          | 4.7 M \n",
      "15 | bn7   | BatchNorm2d     | 2.0 K \n",
      "16 | conv8 | Conv2d          | 9.4 M \n",
      "17 | bn8   | BatchNorm2d     | 2.0 K \n",
      "18 | conv9 | Conv2d          | 30.8 K\n",
      "-------------------------------------------\n",
      "9.5 M     Trainable params\n",
      "6.3 M     Non-trainable params\n",
      "15.8 M    Total params\n",
      "63.058    Total estimated model params size (MB)\n",
      "c:\\Users\\Michael\\miniconda3\\envs\\embedded-ml\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\Michael\\miniconda3\\envs\\embedded-ml\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\Michael\\miniconda3\\envs\\embedded-ml\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c1e234b5ef41b8b6984989d11d008f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michael\\miniconda3\\envs\\embedded-ml\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31afa0acf22462daa8a2b81e3e23e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.tune(model, data)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ap import precision_recall_levels, ap, display_roc\n",
    "from utils.yolo import nms, filter_boxes\n",
    "from utils.dataloader import VOCDataLoaderPerson\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "\n",
    "test_loader = VOCDataLoaderPerson(train=False, batch_size=1, data_path=DATA_PATH, n_limit=350)\n",
    "\n",
    "test_precision = []\n",
    "test_recall = []\n",
    "\n",
    "for inputs, targets in tqdm.tqdm(test_loader, total=350):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "\n",
    "    #The right threshold values can be adjusted for the target application\n",
    "    outputs = filter_boxes(outputs, 0.0)\n",
    "    outputs = nms(outputs, 0.5)\n",
    "    outputs = torch.tensor(np.array(outputs))\n",
    "\n",
    "    precision, recall = precision_recall_levels(targets[0], outputs[0])\n",
    "    test_precision.append(precision)\n",
    "    test_recall.append(recall)\n",
    "\n",
    "avg_precision = ap(test_precision, test_recall)\n",
    "print(\"average precision: \", avg_precision)\n",
    "display_roc(test_precision, test_recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbfbde83ea5ffc555830b2add588da7cea02368f7c2cdb0f2f81ff2a0f3ac2ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
