{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d75f4e1c-1203-4ec8-98ca-1e40d9504b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.camera import CameraDisplay\n",
    "import time\n",
    "import cv2\n",
    "import onnxruntime as ort\n",
    "import torchvision.transforms.functional as tf\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from utils.dataloader import image_transform\n",
    "from utils.viz import plot_predictions\n",
    "now = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378c90fe-d300-44ef-b94d-a2ee0f9deee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a callback function (your detection pipeline)\n",
    "# Make sure to first load all your pipeline code and only at the end init the camera\n",
    "model_file = \"pretrained.onnx\"\n",
    "sess_options = ort.SessionOptions()\n",
    "sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "ort_sess = ort.InferenceSession('data/'+model_file, sess_options=sess_options, providers=['CUDAExecutionProvider'])\n",
    "\n",
    "def predict(image):\n",
    "    image = Image.fromarray(image)\n",
    "    image = image_transform(image)[0]\n",
    "    image = tf.to_tensor(image)\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    onnx_predictions = ort_sess.run(None, {\"input.1\": image.numpy()})[0]\n",
    "    return plot_predictions(onnx_predictions, image, return_array=True)\n",
    "\n",
    "\n",
    "def callback(image):\n",
    "    global now\n",
    "\n",
    "    fps = f\"{int(1/(time.time() - now))}\"\n",
    "    now = time.time()\n",
    "    image = predict(image)\n",
    "    cv2.putText(image, \"fps=\"+fps, (2, 25), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (100, 255, 0), 2, cv2.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b04faf9-2199-4048-99f5-38800d60db46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing camera...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fc2b27fb514fbf9cd779c238f3891a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the camera with the callback\n",
    "cam = CameraDisplay(callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e75dcda4-6d16-416d-a40c-b0405dca42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The camera stream can be started with cam.start()\n",
    "# The callback gets asynchronously called (can be stopped with cam.stop())\n",
    "cam.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f55b1d-78d1-46f1-8ff8-11e0fc7689ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol\n",
      "lol\n",
      "Camera released\n"
     ]
    }
   ],
   "source": [
    "# The camera should always be stopped and released for a new camera is instantiated (calling CameraDisplay(callback) again)\n",
    "cam.stop()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3796677-140d-4a9c-afd4-d31b5843b4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
