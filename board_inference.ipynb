{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d75f4e1c-1203-4ec8-98ca-1e40d9504b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.camera import CameraDisplay\n",
    "import time\n",
    "import cv2\n",
    "import onnxruntime as ort\n",
    "import torchvision.transforms.functional as tf\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from utils.dataloader import image_transform\n",
    "from utils.viz import plot_predictions\n",
    "\n",
    "from models.tinyyolov2 import TinyYoloV2Original, TinyYoloV2PersonOnly\n",
    "from torch.quantization import fuse_modules\n",
    "now = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a14a627-1860-4cf8-9d81-e5245b1f9d13",
   "metadata": {},
   "source": [
    "# Full Yolo Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b877fb0f-2e9d-42b3-9cdc-52c89e899ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyYoloV2Original()\n",
    "model.load_pt_from_disk(\"data/voc_pretrained.pt\", discard_last_layer=False)\n",
    "\n",
    "def predict(image):\n",
    "    image = Image.fromarray(image)\n",
    "    image = image_transform(image)[0]\n",
    "    image = tf.to_tensor(image)\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(image)\n",
    "    return plot_predictions(predictions, image, return_array=True)\n",
    "\n",
    "def callback(image):\n",
    "    global now\n",
    "\n",
    "    fps = f\"{int(1/(time.time() - now))}\"\n",
    "    now = time.time()\n",
    "    image = predict(image)[70:-70]\n",
    "    cv2.putText(image, \"fps=\"+fps, (2, 25), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (100, 255, 0), 2, cv2.LINE_AA)\n",
    "    return image\n",
    "\n",
    "# Initialize the camera with the callback\n",
    "cam = CameraDisplay(callback)\n",
    "cam.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb51f96a-a97b-440f-8d03-93263d7b3376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera released\n"
     ]
    }
   ],
   "source": [
    "cam.stop()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ea62ab-b1c0-43ef-9eee-1068129d5b33",
   "metadata": {},
   "source": [
    "# Person Only Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c2ceaa-66b3-4163-902a-2f3908722375",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyYoloV2PersonOnly()\n",
    "model.load_state_dict(torch.load(\"data/person_only.pt\"), strict=False)\n",
    "\n",
    "def predict(image):\n",
    "    image = Image.fromarray(image)\n",
    "    image = image_transform(image)[0]\n",
    "    image = tf.to_tensor(image)\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(image)\n",
    "    return plot_predictions(predictions, image, return_array=True, person_only=True)\n",
    "\n",
    "def callback(image):\n",
    "    global now\n",
    "\n",
    "    fps = f\"{int(1/(time.time() - now))}\"\n",
    "    now = time.time()\n",
    "    image = predict(image)[70:-70]\n",
    "    cv2.putText(image, \"fps=\"+fps, (2, 25), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (100, 255, 0), 2, cv2.LINE_AA)\n",
    "    return image\n",
    "\n",
    "# Initialize the camera with the callback\n",
    "cam = CameraDisplay(callback)\n",
    "cam.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90d949fd-115a-4369-bcb0-6f033bbb8ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera released\n"
     ]
    }
   ],
   "source": [
    "cam.stop()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf4316f-666b-4ef6-b912-da9d4d6aa8b5",
   "metadata": {},
   "source": [
    "# Person Only Torch Fused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73460055-16e0-4d2a-87ea-542eeb6deb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyYoloV2PersonOnly()\n",
    "model.load_state_dict(torch.load(\"data/person_only.pt\"), strict=False)\n",
    "modules = [name for name, _ in model.named_modules()][5:-1]\n",
    "modules_to_fuse = [modules[i:i + 2] for i in range(0, len(modules), 2)]\n",
    "fuse_modules(model, modules_to_fuse, inplace=True)\n",
    "\n",
    "def predict(image):\n",
    "    image = Image.fromarray(image)\n",
    "    image = image_transform(image)[0]\n",
    "    image = tf.to_tensor(image)\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(image)\n",
    "    return plot_predictions(predictions, image, return_array=True, person_only=True)\n",
    "\n",
    "def callback(image):\n",
    "    global now\n",
    "\n",
    "    fps = f\"{int(1/(time.time() - now))}\"\n",
    "    now = time.time()\n",
    "    image = predict(image)[70:-70]\n",
    "    cv2.putText(image, \"fps=\"+fps, (2, 25), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (100, 255, 0), 2, cv2.LINE_AA)\n",
    "    return image\n",
    "\n",
    "# Initialize the camera with the callback\n",
    "cam = CameraDisplay(callback)\n",
    "cam.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc5cfe2f-7f9d-4347-8ad5-46917ba466e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera released\n"
     ]
    }
   ],
   "source": [
    "cam.stop()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186f6d57-afad-49c3-9167-72652dccedfd",
   "metadata": {},
   "source": [
    "# Full Yolo Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378c90fe-d300-44ef-b94d-a2ee0f9deee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"pretrained.onnx\"\n",
    "sess_options = ort.SessionOptions()\n",
    "sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "ort_sess = ort.InferenceSession('data/'+model_file, sess_options=sess_options, providers=['CUDAExecutionProvider'])\n",
    "\n",
    "def predict(image):\n",
    "    image = Image.fromarray(image)\n",
    "    image = image_transform(image)[0]\n",
    "    image = tf.to_tensor(image)\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    onnx_predictions = ort_sess.run(None, {\"input.1\": image.numpy()})[0]\n",
    "    return plot_predictions(onnx_predictions, image, return_array=True)\n",
    "\n",
    "\n",
    "def callback(image):\n",
    "    global now\n",
    "\n",
    "    fps = f\"{int(1/(time.time() - now))}\"\n",
    "    now = time.time()\n",
    "    image = predict(image)[70:-70]\n",
    "    cv2.putText(image, \"fps=\"+fps, (2, 25), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (100, 255, 0), 2, cv2.LINE_AA)\n",
    "    return image\n",
    "\n",
    "# Initialize the camera with the callback\n",
    "cam = CameraDisplay(callback)\n",
    "cam.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b04faf9-2199-4048-99f5-38800d60db46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera released\n"
     ]
    }
   ],
   "source": [
    "cam.stop()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8284ffe4-8026-4038-bbce-b57c93d051ea",
   "metadata": {},
   "source": [
    "# Person Only Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feefdf9c-f063-4342-aadd-c95a6b4a32de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"person_only.onnx\"\n",
    "sess_options = ort.SessionOptions()\n",
    "sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "ort_sess = ort.InferenceSession('data/'+model_file, sess_options=sess_options, providers=['CUDAExecutionProvider'])\n",
    "\n",
    "def predict(image):\n",
    "    image = Image.fromarray(image)\n",
    "    image = image_transform(image)[0]\n",
    "    image = tf.to_tensor(image)\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    onnx_predictions = ort_sess.run(None, {\"input.1\": image.numpy()})[0]\n",
    "    return plot_predictions(onnx_predictions, image, return_array=True, person_only=True)\n",
    "\n",
    "\n",
    "def callback(image):\n",
    "    global now\n",
    "\n",
    "    fps = f\"{int(1/(time.time() - now))}\"\n",
    "    now = time.time()\n",
    "    image = predict(image)[70:-70]\n",
    "    cv2.putText(image, \"fps=\"+fps, (2, 25), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (100, 255, 0), 2, cv2.LINE_AA)\n",
    "    return image\n",
    "\n",
    "# Initialize the camera with the callback\n",
    "cam = CameraDisplay(callback)\n",
    "cam.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea534768-9903-4412-b742-802945f1b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.stop()\n",
    "cam.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
