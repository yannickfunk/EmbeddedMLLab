{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yannickfunk/EmbeddedMLLab/blob/main/end2end.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "n8H5SAnBs7kr",
    "outputId": "9813d84a-7a45-44f0-b27d-b84533db6556",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "# if in colab, make colab setup\n",
    "if 'google.colab' in sys.modules:\n",
    "    FILENAME = \"end2end.ipynb\"\n",
    "    BRANCH = \"main\"\n",
    "    !git clone -b $BRANCH https://github.com/yannickfunk/EmbeddedMLLab tmp\n",
    "    !rm tmp/$FILENAME\n",
    "    !mv tmp/* .\n",
    "    !rm -rf tmp\n",
    "    !rm -rf sample_data\n",
    "    !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "S0zxFY0Kucyw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar to data/VOCtrainval_11-May-2012.tar\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1999639040 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78f7c5e0ab524002a2ca9f8b67c6b64a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/VOCtrainval_11-May-2012.tar to data/\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'voc_pretrained.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 15\u001B[0m\n\u001B[1;32m     12\u001B[0m net \u001B[38;5;241m=\u001B[39m TinyYoloV2(num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# load pretrained weights\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m sd \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvoc_pretrained.pt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m net\u001B[38;5;241m.\u001B[39mload_state_dict(sd)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m#put network in evaluation mode\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/embedded-ml/lib/python3.10/site-packages/torch/serialization.py:771\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001B[0m\n\u001B[1;32m    768\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    769\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 771\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[1;32m    772\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[1;32m    773\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[1;32m    774\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[1;32m    775\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[1;32m    776\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[0;32m~/anaconda3/envs/embedded-ml/lib/python3.10/site-packages/torch/serialization.py:270\u001B[0m, in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    268\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[1;32m    269\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[0;32m--> 270\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    272\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[0;32m~/anaconda3/envs/embedded-ml/lib/python3.10/site-packages/torch/serialization.py:251\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[0;32m--> 251\u001B[0m     \u001B[38;5;28msuper\u001B[39m(_open_file, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'voc_pretrained.pt'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "\n",
    "from utils.dataloader import VOCDataLoader\n",
    "from models.tinyyolov2 import TinyYoloV2\n",
    "from utils.yolo import nms, filter_boxes\n",
    "from utils.viz import display_result\n",
    "\n",
    "loader = VOCDataLoader(train=False, batch_size=1)\n",
    "\n",
    "# make an instance with 20 classes as output\n",
    "net = TinyYoloV2(num_classes=20)\n",
    "\n",
    "# load pretrained weights\n",
    "sd = torch.load(\"voc_pretrained.pt\")\n",
    "net.load_state_dict(sd)\n",
    "\n",
    "#put network in evaluation mode\n",
    "net.eval()\n",
    "for idx, (input, target) in tqdm.tqdm(enumerate(loader), total=len(loader)):\n",
    "\n",
    "    #input is a 1 x 3 x 320 x 320 image\n",
    "    output = net(input)\n",
    "    \"output is of a tensor of size 32 x 125 x 10 x 10\"\n",
    "    #output is a 32 x 125 x 10 x 10 tensor\n",
    "\n",
    "    #filter boxes based on confidence score (class_score*confidence)\n",
    "    output = filter_boxes(output, 0.1)\n",
    "\n",
    "    #filter boxes based on overlap\n",
    "    output = nms(output, 0.25)\n",
    "\n",
    "    display_result(input, output, target, file_path='yolo_prediction.png')"
   ],
   "metadata": {
    "id": "tKPucx8rs7ks",
    "outputId": "9c17118a-d1f0-466d-9bc9-0c71bf30e929",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "m-qM3c6ls7ks"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "c3IiNIjKs7kt"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
